---
format: 
   revealjs:
    embed-resources: true
    theme: serif
    slide-level: 3
    slide-number: true
    show-slide-number: all
    preview-links: auto
    number-sections: true
    link-color: orange
title: "Design declaration, diagnosis, and redesign "
subtitle: "MIDA and more"
author: "Graeme Blair, Alex Coppock, Macartan Humphreys"
bibliography: bib.bib
---

# `DeclareDesign` Basics {#secdd}

*How to define and assess research designs* 

## Roadmap

1. The MIDA framework and the declaration-diagnosis-redesign cycle
2. `DeclareDesign`: key resources
3. The Declare-Diagnose-Redesign life cycle
4. Using designs
5. Hands-on declaration and diagnosis
6. Illustration using power calculations


```{r, include=FALSE}
source("setup.R")
run <- FALSE
```



## The MIDA Framework {#MIDAframework}

### Four elements of any research design

- `Model`: set of models of what causes what and how
- `Inquiry`: a question stated in terms of the model
- `Data strategy`: the set of procedures we use to gather information from the world (sampling, assignment, measurement)
- `Answer strategy`: how we summarize the data produced by the data strategy

### Four elements of any research design

```{r midaplot, echo = FALSE}
knitr::include_graphics("assets/mida.png")
```

### Declaration

Design declaration is telling the computer (and readers) what `M`, `I`, `D`, and `A` are.

### Diagnosis

* Design diagnosis is figuring out how the design will perform under imagined conditions.

* Estimating "diagnosands" like power, bias, rmse, error rates, ethical harm, "amount learned".

*  Diagnosis takes account of model uncertainty: it aims  to identify models for which the design works well and models for which it does not

### Redesign 

Redesign is the fine-tuning of  features of the data- and answer strategies to understand how changing them affects  the diagnosands

* Different sample sizes
* Different randomization procedures
* Different estimation strategies
* Implementation: effort into compliance versus more effort into sample size

### Very often you have to simulate!

* Doing all this is often too hard to work out from rules of thumb or power calculators
* Specialized formulas exist for some diagnosands, but not all


## DeclareDesign: Overview of key functions and resources


### Key commands for making a design

* `declare_model()`
* `declare_inquiry()`

* `declare_sampling()`
* `declare_assignment()`
* `declare_measurement()`

* `declare_estimator()`

and there are more `declare_` functions!

### Key commands for using a design

* `draw_data(design)`
* `draw_estimands(design)`
* `draw_estimates(design)`
* `get_estimates(design, data)`
* `run_design(design)`, `simulate_design(design)`
* `diagnose_design(design)`
* `redesign(design, N = 200)`
* `compare_designs()`, `compare_diagnoses()`

### Pipeable commands

```{r, echo = TRUE, eval = FALSE}
design |> 
  redesign(N = c(200, 400)) |>
  diagnose_designs() |> 
  tidy() |> 
  ggplot(...) 
```


### Cheat sheet

[https://raw.githubusercontent.com/rstudio/cheatsheets/master/declaredesign.pdf](https://raw.githubusercontent.com/rstudio/cheatsheets/master/declaredesign.pdf)


```{r, echo = FALSE}
knitr::include_graphics("assets/cheat_sheet.png") 
```

### Other resources

* The website: https://declaredesign.org/
* The book: https://book.declaredesign.org
* The console: `?DeclareDesign`

## Design declaration-diagnosis-redesign workflow: Design

### The simplest possible (diagnosable) design?

```{r}
mean <- 0
simplest_design <- 
  declare_model(N = 100, Y = rnorm(N, mean)) +
  declare_inquiry(Q = mean) +
  declare_estimator(Y ~ 1)
```

* we draw 100 units from a standard normal distribution
* we define our inquiry as the *population expectation*
* we estimate the average using a regression with a constant term


### The simplest possible design?


```{r}
simplest_design <- 
  declare_model(N = 100, Y = rnorm(N, mean)) +
  declare_inquiry(Q = 0) +
  declare_estimator(Y ~ 1)

```

* This design has three steps, with steps connected by a `+`
* The design itself is just a list of steps and has class `design`

```{r, echo = FALSE}
if(run)
  simplest_design |>
  diagnose_design() |>
  write_rds("saved/simplest_design.rds")
```


```{r}
str(simplest_design)
```


### The simplest possible design? It's a pipe

Each step is a function (or rather: a function that generates functions) and each function presupposes what is created by previous functions. 

* The ordering of steps is quite important
* Most steps take the `main` data frame in and push the `main` dataframe out; this data frame normally builds up as you move along the pipe. 


### The simplest possible design? It's a pipe

Each step is a function (or rather: a function that generates functions) and each function presupposes what is created by previous functions. 

* The ordering of steps is quite important
* `declare_estimator`  steps take the `main` data frame in and send out an `estimator_df` dataframe 
* `declare_inquiry`  steps take the `main` data frame in and send out an `estimand_df` dataframe. 


### The simplest possible design? It's a pipe

* You can run these functions one at a time if you like.
* For instance the third step presupposes the data from the first step:


```{r}
df <- simplest_design[[1]]()
A  <- simplest_design[[3]](df)

A |> kable(digits = 2) |> kable_styling(font_size = 20)

Estimand  <- simplest_design[[2]](df)

Estimand |> kable(digits = 2) |> kable_styling(font_size = 20)

```


### The simplest possible design? Run it once

You can also just run through the whole design once by typing the name of the design:

```{r}
simplest_design
```

### The simplest possible design? Run it again

Or by asking for a run of the design

```{r}
one_run <- simplest_design |> run_design()
one_run |> kable(digits = 2) |> kable_styling(font_size = 18)
```

A single run creates data, calculates estimands (the answer to inquiries) and calculates estimates plus ancillary statistics.

### The simplest possible design?: Simulation


Or by asking for a run of the design

```{r, warning = FALSE}
some_runs <- simplest_design |> simulate_design(sims = 1000)
some_runs |> kable(digits = 2) |> kable_styling(font_size = 16)
```


### The simplest possible design?: Diagnosis

Once you have simulated many times you can "diagnose".

This is the next topic

## Design declaration-diagnosis-redesign workflow: Diagnosis

### Diagnosis by hand

Once you have simulated many times you can "diagnose".

For instance we can ask about bias: the average difference between the estimand and the estimate:

```{r, eval = FALSE}
some_runs |> mutate(error = estimate - estimand) |>
  summarize(mean_estimate = mean(estimate), 
            mean_estimand = mean(estimand), 
            bias = mean(error)) 
```

```{r, echo = FALSE}
some_runs |> mutate(error = estimate - estimand) |>
  summarize(mean_estimate = mean(estimate), 
            mean_estimand = mean(estimand), 
            bias = mean(error)) |>
  kable(digits= 2) |> 
  kable_styling(font_size = 20)
```

### The simplest possible design?

`diagnose_design()` does this in one step for a set of common  "diagnosands":


```{r, eval = FALSE}
diagnosis <-
  simplest_design |>
  diagnose_design()
```



```{r, echo = FALSE}

if(run)
  simplest_design |>
  diagnose_design() |>
  write_rds("saved/simplest_design.rds")

diagnosis <- read_rds("saved/simplest_design.rds") 

diagnosis |>
  reshape_diagnosis() |>
  select(-Inquiry, -Estimator, -Outcome, -Term) |>
  kable() |> kable_styling(font_size = 20)

```

### What is the diagnosis object?

The diagnosis object is also a list; of class `diagnosis`

```{r}
names(diagnosis)
class(diagnosis)
```

### What is the diagnosis object?

```{r, eval = FALSE}
diagnosis$simulations_df |> 
  head() 

```

```{r, echo = FALSE}
diagnosis$simulations_df |> 
  head() |> kable(digits = 2) |> kable_styling(font_size = 16)

```

### What is the diagnosis object?

```{r, eval = FALSE}
diagnosis$diagnosands_df |> 
  head() 
```


```{r, echo = FALSE}
diagnosis$diagnosands_df |> 
  head() |> kable(digits = 2) |> kable_styling(font_size = 16)
```
### What is the diagnosis object?

```{r, eval = FALSE}
diagnosis$bootstrap_replicates |> 
  head()
```


```{r, echo = FALSE}
diagnosis$bootstrap_replicates |> 
  head() |> kable(digits = 2) |> kable_styling(font_size = 16)
```

### Diagnosis: Bootstraps

* The bootstraps dataframe is produced by resampling from the simulations dataframe and producing a diagnosis dataframe from each resampling. 

* This lets us generate estimates of uncertainty around our diagnosands.

* It can be controlled thus:

```{r, eval = FALSE}

diagnose_design(
  ...,
  bootstrap_sims = 100
)
```


### After Diagnosis 

It's reshapeable: as a tidy dataframe, ready for graphing

```{r, eval = FALSE}
diagnosis |> 
  tidy() 
```

```{r, echo = FALSE}
diagnosis |> 
  tidy() |> kable(digits = 2) |> kable_styling(font_size = 18)
```

### After Diagnosis 

It's reshapeable: as a tidy dataframe, ready for graphing

```{r, fig.width = 6, fig.height = 2}
diagnosis |> 
  tidy() |> 
  ggplot(aes(estimate, diagnosand)) + geom_point() + 
  geom_errorbarh(aes(xmax = conf.high, xmin = conf.low, height = .2))
```



### After Diagnosis: Tables 

Or turn into a formatted table:

```{r, eval = FALSE}
diagnosis |> 
  reshape_diagnosis() 
```

```{r, echo = FALSE}
diagnosis |> 
  reshape_diagnosis() |> kable() |> kable_styling(font_size = 18)
```

### Advanced Diagnosis: Variations

```{r, eval = FALSE}
DeclareDesign:::default_diagnosands
```

```{r, eval = FALSE}
    mean_estimand <- mean(estimand)
    mean_estimate <- mean(estimate)
    bias <- mean(estimate - estimand)
    sd_estimate <- sd(estimate)
    rmse <- sqrt(mean((estimate - estimand)^2))
    power <- mean(p.value <= alpha)
    coverage <- mean(estimand <= conf.high & estimand >= conf.low)
```


### Advanced Diagnosis:  Other diagnosands

```{r, eval = FALSE}

    mean_se = mean(std.error)
    type_s_rate = mean((sign(estimate) != sign(estimand))[p.value <= alpha])
    exaggeration_ratio = mean((estimate/estimand)[p.value <= alpha])
    var_estimate = pop.var(estimate)
    mean_var_hat = mean(std.error^2)
    prop_pos_sig = estimate > 0 & p.value <= alpha
    mean_ci_length = mean(conf.high - conf.low)

```

### Advanced Diagnosis: Custom diagnosands

```{r, warning = FALSE}

my_diagnosands <-
  declare_diagnosands(median_bias = median(estimate - estimand))

diagnose_design(simplest_design, diagnosands = my_diagnosands, sims = 10) |>
  reshape_diagnosis() |> kable() |> kable_styling(font_size = 20)
```

### Advanced Diagnosis: Adding diagnosands to a design

```{r, warning = FALSE}
simplest_design <- 
  set_diagnosands(simplest_design, my_diagnosands)

simplest_design |> diagnose_design(sims = 10)|>
  reshape_diagnosis() |> kable() |> kable_styling(font_size = 20)

```


### Advanced Diagnosis:  Diagnosing multiple designs

You can diagnose multiple designs or a list of designs

```{r, warning = FALSE}

list(dum = simplest_design, dee = simplest_design) |>
  diagnose_design(sims = 5) |>
  reshape_diagnosis() |> 
  kable() |> 
  kable_styling(font_size = 20)
```

### Advanced Diagnosis:  Diagnosing in groups {.smaller}


You can partition the simulations data frame into groups before calculating diagnosands. 

```{r, eval = FALSE}
grouped_diagnosis <- 
  
  simplest_design |>
  diagnose_design(
    make_groups = vars(significant = p.value <= 0.05),
    sims = 500
  )
```


```{r, echo = FALSE}
if(run)
  simplest_design |>
  
  
  set_diagnosands() |>

    diagnose_design(
    make_groups = vars(significant = p.value <= 0.05),
    sims = 500
  ) |>
  write_rds("saved/group_rep.rds")

grouped_diagnosis <-   read_rds("saved/group_rep.rds") 

grouped_diagnosis |>
  reshape_diagnosis() |>
  select(-Inquiry, - Estimator, -Outcome, -Term) |>
  kable(digits = 2) |> 
  kable_styling(font_size = 20)

```

Note especially the mean estimate,  the power, the coverage, the RMSE, and the bias.
(Bias is not large because we have both under and over estimates)

### Significance filter

```{r, fig.height = 2, fig.width = 6}
grouped_diagnosis$simulations_df |>
  ggplot(aes(estimate, p.value, color = significant)) + geom_point()
```

### Advanced Diagnosis: Multistage simulation 

* Usually a design simulation simulates "from the top": going from the beginning to the end of the design in each run and repeating
* But sometimes you might want to follow a tree like structure and simulate different steps a different number of times

### Advanced Diagnosis: Multistage simulation 

Consider for instance this sampling design:

```{r}
sampling_design <- 
  
  declare_model(N = 500, Y = 1 + rnorm(N, sd = 10)) +
  declare_inquiry(Q = mean(Y)) +
  declare_sampling(S = complete_rs(N = N, n = 100)) + 
  declare_estimator(Y ~ 1)

```


### Advanced Diagnosis: Multistage simulation 

Compare these two diagnoses:

```{r, warning = FALSE, eval = FALSE}
diagnosis_1 <- diagnose_design(sampling_design, sims = c(5000, 1, 1, 1)) 
diagnosis_2 <- diagnose_design(sampling_design, sims = c(1, 5000, 1, 1))
```



```{r, warning = FALSE, echo = FALSE}
if(run){
set.seed(1)
diagnose_design(sampling_design, sims = c(5000, 1, 1, 1)) |> write_rds("saved/multistage1.rds") 
diagnose_design(sampling_design, sims = c(1, 5000, 1, 1)) |> write_rds("saved/multistage2.rds")
}

list(diagnosis_1 = read_rds("saved/multistage1.rds") |> reshape_diagnosis(),
     diagnosis_2 = read_rds("saved/multistage2.rds") |> reshape_diagnosis()) |>
  bind_rows(.id = "diagnosis") |>
  select(-Design, -Inquiry, -Estimator, -Outcome, -Term) |>
  kable(digits = 2) |> 
  kable_styling(font_size = 20)
     

```

In the second the estimate is drawn just once. The SD of the estimate is lower. But the RMSE is not very different. 

### Spotting design problems with diagnosis

Diagnosis alerts to problems in a design. Consider the following simple alternative design.


```{r}
simplest_design_2 <- 
  
  declare_model(N = 100, Y = rnorm(N)) +
  declare_inquiry(Q = mean(Y)) +
  declare_estimator(Y ~ 1)

```

Here we define the inquiry as the sample average $Y$ (instead of the population mean). But otherwise things stay the same. 

What do we think of this design?

### Spotting design problems with diagnosis

Here is the diagnosis

```{r, echo = FALSE}
if(run)
  simplest_design_2 |>
  diagnose_design() |>
  write_rds("saved/simplest_design_2.rds")
```

```{r, echo = FALSE}

read_rds("saved/simplest_design_2.rds") |>
  reshape_diagnosis() |>
  select(-Inquiry, -Estimator, -Outcome, -Term) |>
  kable() |> 
  kable_styling(font_size = 20)

```


* Why is coverage so high? is that OK?
* Why is the RMSE 0 but the SD of the estimate  > 0?  is that OK?
   * Is it because the RMSE is too low?
   * Or the standard error is too large?


### It depends on the inquiry

* If we are really interested in the sample average then our standard error is off: *we should have no error at all!*
* If we are really interested in the population average then our inquiry is badly defined: *it should not be redefined on each run!*


## Design declaration-diagnosis-redesign workflow: Redesign

### Redesign

Redesign is the process of taking a design and modifying it in some way.

There are a few ways to do this:

1. Just make a new design using modified code
2. Take a design and alter some steps using `replace_step`, `insert_step` or `delete_step`
3. Modify a design *parameter* using `redesign`

we will focus on the third approach

### Redesign {.smaller}

* A design parameter is a modifiable quantity of a design. 
* These quantities are objects that were in your global environment when you made your design, get referred to explicitly in your design, and got scooped up when the design was formed.

* In our simplest design above we had a fixed `N`, but we could make `N`  a modifiable quantity like this:


```{r}
N <- 100

simplest_design_N <- 
  
  declare_model(N = N, Y = rnorm(N)) +
  declare_inquiry(Q = 0) +
  declare_estimator(Y ~ 1)

```

### Redesign


```{r}
N <- 100

simplest_design_N <- 
  
  declare_model(N = N, Y = rnorm(N)) +
  declare_inquiry(Q = 0) +
  declare_estimator(Y ~ 1)

```


Note that `N` is defined in memory; and it gets called in one of the steps. It has now become a parameter of the design and it can be modified using redesign. 

### Simple Redesign

Here is a version of the design with `N = 200`:

```{r}

design_200 <- simplest_design_N |> redesign(N = 200)
  
design_200 |> draw_data() |> nrow()

```



### Redesigning to a list

Here is a list of three different designs with different *N*s.

```{r}
design_Ns <- simplest_design_N |> redesign(N = c(200, 400, 800))

design_Ns |> lapply(draw_data) |> lapply(nrow)
```

### Redesigning to a list

The good thing here is that it is now easy to diagnose over multiple designs and compare diagnoses. The parameter names then end up in the `diagnosis_df`

Consider this:


```{r}
N <- 100
m <- 0

design <- 
  declare_model(N = N, Y = rnorm(N, m)) +
  declare_inquiry(Q = m) +
  declare_estimator(Y ~ 1) 
```

Then:

```{r, eval = FALSE}
designs <-  redesign(design, N = c(100, 200, 300), m = c(0, .1, .2))
  
designs |> diagnose_design() |> tidy() 
```

### Redesigning to a list

Output:

```{r, eval = FALSE}
designs |> diagnose_design() |> tidy() 
```

```{r, echo = FALSE}
if(run)
  redesign(design, N = c(100, 200, 300), m = c(0, .1, .2)) |> diagnose_design() |> tidy() |> write_rds("saved/redesigns.rds")

read_rds("saved/redesigns.rds") |>
  select(N, m, diagnosand, estimate, std.error, conf.low, conf.high) |>  slice(c(1:4, 8:9, 29:30, 59:63)) |>           
  kable(digits = 2) |> 
  kable_styling(font_size = 20)
```

  
### Redesigning to a list

Graphing after redesign is especially easy:


```{r, eval = FALSE}
designs |> diagnose_design() |> 
  tidy() |>
  filter(diagnosand %in% c("power", "rmse")) |> 
  ggplot(aes(N, estimate, color = factor(m))) + 
  geom_line() + 
  facet_wrap(~diagnosand)
```


```{r, echo = FALSE, fig.cap = "Power depends on N and m, rmse depends on N only", fig.height = 2, fig.width = 6}
read_rds("saved/redesigns.rds") |>
  filter(diagnosand %in% c("power", "rmse")) |> 
  ggplot(aes(N, estimate, color = factor(m))) + 
  geom_line() + 
  facet_wrap(~diagnosand)
```

### Redesign with vector arguments

When redesigning with arguments that are vectors,
use `list()` in redesign, with each list item representing a design you wish to create

```{r, eval = FALSE}

prob_each <- c(.1, .5, .4)

design_multi  <- 
  declare_model(N = 10) +
  declare_assignment(Z = complete_ra(N = N, prob_each = prob_each))

## returns two designs

designs <- design_multi |> 
  redesign(prob_each = list(c(.2, .5, .3), c(0, .5, .5)))
  
designs |> lapply(draw_data)
```


### Redesign warnings


A parameter has to be called correctly. And you get no warning if you misname.

```{r}
simplest_design_N  |> redesign(n = 200) |> draw_data() |> nrow()
```

why not 200?

### Redesign warnings


A parameter has to be called explicitly

```{r}
N <- 100

my_N <- function(n = N) n

simplest_design_N2 <- 
  
  declare_model(N = my_N(), Y = rnorm(N)) +
  declare_inquiry(Q = 0) +
  declare_estimator(Y ~ 1)

simplest_design_N2 |> redesign(N = 200) |> draw_data() |> nrow()
```

why not 200?

### Redesign warnings


A parameter has to be called explicitly

```{r}
N <- 100

my_N <- function(n = N) n

simplest_design_N2 <- 
  
  declare_model(N = my_N(N), Y = rnorm(N)) +
  declare_inquiry(Q = 0) +
  declare_estimator(Y ~ 1)

simplest_design_N2 |> redesign(N = 200) |> draw_data() |> nrow()
```


OK

### Redesign with a function

Here is an example of redesigning where the "parameter" is a function

```{r}
new_N <- function(n, factor = 1.31) n*factor

simplest_design_N2 |> redesign(my_N = new_N) |> draw_data() |> nrow()

```



## Using a design

What can you do with a design once you have it?

We will start with a very simple experimental design (more on the components of this later)

```{r}
b <-1
N <- 100
design <- 
  declare_model(N = N, U = rnorm(N), potential_outcomes(Y ~ b * Z + U)) + 
  declare_assignment(Z = simple_ra(N), Y = reveal_outcomes(Y ~ Z)) + 
  declare_inquiry(ate = mean(Y_Z_1 - Y_Z_0)) + 
  declare_estimator(Y ~ Z, inquiry = "ate", .method = lm_robust)
```


### Make data from the design

```{r}
data <- draw_data(design)

data |> head () |> kable() |> kable_styling(font_size = 20)
```

### Make data from the design

Play with the data:

```{r, comment = ""}
lm_robust(Y ~ Z, data = data) |>
  tidy() |>
  kable(digits = 2) |> 
  kable_styling(font_size = 20)

```

### Draw estimands


```{r, comment = ""}

draw_estimands(design) |>
  kable(digits = 2) |> 
  kable_styling(font_size = 20)

```

### Draw estimates


```{r, comment = ""}

draw_estimates(design) |> 
  kable(digits = 2) |> 
  kable_styling(font_size = 20)

```


### Get estimates

Using your actual data:

```{r, comment = ""}

get_estimates(design, data) |>
  kable(digits = 2) |> 
  kable_styling(font_size = 20)

```

### Simulate design

```{r, comment = "", warning = FALSE}

simulate_design(design, sims = 3) |>
  kable(digits = 2) |> 
  kable_styling(font_size = 16)

```

### Diagnose design

```{r, eval = FALSE, message = FALSE}

design |> 
  diagnose_design(sims = 100) 

```

```{r, echo = FALSE, message = FALSE}

design |> 
  diagnose_design(sims = 100) |>
  reshape_diagnosis() |>
  select("Mean Estimate", "Bias", "SD Estimate", "RMSE", "Power", "Coverage" ) |>
  kable(digits = 2) |> 
  kable_styling(font_size = 20)

```

### Redesign

```{r, comment = "", message = FALSE}

new_design <-
  
  design |> redesign(b = 0)

```

* Modify any arguments that are explicitly called on by design steps.
* Or add, remove, or replace steps


### Compare designs

```{r, eval = FALSE}
redesign(design, N = 50) %>%
  
  compare_diagnoses(design) 

```


```{r, echo = FALSE}
if(run)
redesign(design, N = 50) %>%
  compare_diagnoses(design)  %>%
  write_rds("saved/compare_diagnoses.rds")

  read_rds("saved/compare_diagnoses.rds")$compared_diagnoses_df |>
    select(-design_1, -design_2, -inquiry, -estimator, -term, -se_1, -se_2, -se_difference,
           -sims, -bootstrap_sims) |>
    kable(digits = 2) |> 
    kable_styling(font_size = 20)

```



